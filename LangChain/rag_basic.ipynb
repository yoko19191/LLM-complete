{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æ•°æ®æ£€ç´¢ï¼ˆç»¼è¿°ï¼‰ | ğŸ¦œï¸ğŸ”— LangChain\n",
    "\n",
    "https://techdiylife.github.io/blog/topic.html?category2=t07&blogid=0044\n",
    "\n",
    "https://python.langchain.com/v0.1/docs/modules/data_connection/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ–‡æ¡£åŠ è½½å™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"../data/txt/odyssey.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "text = documents[0].page_content\n",
    "text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ–‡æœ¬åˆ†å‰²å™¨ \n",
    "\n",
    "https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/tutorials/LevelsOfTextSplitting/5_Levels_Of_Text_Splitting.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain-text-splitters \n",
    "\n",
    "# level 1 - Character Splitting\n",
    "# from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# text_splitter = CharacterTextSplitter(\n",
    "#     separator=\"\\n\",\n",
    "#     chunk_size=100,\n",
    "#     chunk_overlap=10\n",
    "# )\n",
    "\n",
    "# text_splitter.create_documents([text])\n",
    "\n",
    "\n",
    "\n",
    "# level 2 - Recursive Character Text Splitting\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size = 150, chunk_overlap=10)\n",
    "# text_splitter.create_documents([text])\n",
    "\n",
    "\n",
    "\n",
    "# level 3 - Document Specific Splitting\n",
    "# from langchain.text_splitter import MarkdownTextSplitter\n",
    "# md_splitter = MarkdownTextSplitter(chunk_size = 40, chunk_overlap=0)\n",
    "\n",
    "# from langchain.text_splitter import PythonCodeTextSplitter\n",
    "# python_splitter = PythonCodeTextSplitter(chunk_size=100, chunk_overlap=0)\n",
    "\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter, Language\n",
    "# js_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "#     language=Language.JS, chunk_size=65, chunk_overlap=0\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PDF elements extraction\n",
    "\n",
    "# Method 1 : basic use of unstructured \n",
    "# !pip3 install \"unstructured[all-docs]\"\n",
    "# import os\n",
    "# from unstructured.partition.pdf import partition_pdf\n",
    "# from unstructured.staging.base import elements_to_json\n",
    "\n",
    "\n",
    "# pdf_path = \"../data/pdf/Attention_is_all_you_need_2017.pdf\"\n",
    "\n",
    "# # Extracts the elements from the PDF\n",
    "# elements = partition_pdf(\n",
    "#     filename=pdf_path,\n",
    "\n",
    "#     # Unstructured Helpers\n",
    "#     strategy=\"hi_res\", \n",
    "#     infer_table_structure=True, \n",
    "#     model_name=\"yolox\" # get bounding boxs (for tables) and find tables\n",
    "# )\n",
    "\n",
    "\n",
    "# for element in elements:\n",
    "#     print(element)\n",
    "    \n",
    "    \n",
    "# Method 2 : use vLLM\n",
    "# from typing import Any\n",
    "\n",
    "# from pydantic import BaseModel\n",
    "# from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "# # Get elements\n",
    "# raw_pdf_elements = partition_pdf(\n",
    "#     filename=pdf_path,\n",
    "    \n",
    "#     # Using pdf format to find embedded image blocks\n",
    "#     extract_images_in_pdf=True,\n",
    "    \n",
    "#     # Use layout model (YOLOX) to get bounding boxes (for tables) and find titles\n",
    "#     # Titles are any sub-section of the document\n",
    "#     infer_table_structure=True,\n",
    "    \n",
    "#     # Post processing to aggregate text once we have the title\n",
    "#     chunking_strategy=\"by_title\",\n",
    "#     # Chunking params to aggregate text blocks\n",
    "#     # Attempt to create a new chunk 3800 chars\n",
    "#     # Attempt to keep chunks > 2000 chars\n",
    "#     # Hard max on chunks\n",
    "#     max_characters=4000,\n",
    "#     new_after_n_chars=3800,\n",
    "#     combine_text_under_n_chars=2000,\n",
    "#     image_output_dir_path=\"static/pdfImages/\",\n",
    "# )\n",
    "\n",
    "\n",
    "# Method 3 : translate image into semantic text \n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.messages import HumanMessage\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from PIL import Image\n",
    "import base64\n",
    "import io\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4-vision-preview\")\n",
    "\n",
    "# Function to convert image to base64\n",
    "def image_to_base64(image_path):\n",
    "    with Image.open(image_path) as image:\n",
    "        buffered = io.BytesIO()\n",
    "        image.save(buffered, format=image.format)\n",
    "        img_str = base64.b64encode(buffered.getvalue())\n",
    "        return img_str.decode('utf-8')\n",
    "\n",
    "image_str = image_to_base64(\"static/pdfImages/figure-15-6.jpg\")\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-4-vision-preview\",\n",
    "                  max_tokens=1024)\n",
    "\n",
    "msg = chat.invoke(\n",
    "    [\n",
    "        HumanMessage(\n",
    "            content=[\n",
    "                {\"type\": \"text\", \"text\" : \"Please give a summary of the image provided. Be descriptive\"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{image_str}\"\n",
    "                    },\n",
    "                },\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "msg.content\n",
    "\n",
    "# Method 4 : https://zhuanlan.zhihu.com/p/706065120 ä½¿ç”¨ vLLM æ¥è§£æPDF æ’ç‰ˆï¼Œæ•°å­¦å…¬å¼ï¼Œè¡¨æ ¼ï¼Œå›¾ç‰‡ï¼Œå›¾è¡¨ æ¥è·å¾— Markdown æ–‡ä»¶\n",
    "# from gptpdf import parse_pdf # pip install gptpdf\n",
    "# api_key = 'Your OpenAI API Key'\n",
    "# content, image_paths = parse_pdf(pdf_path, api_key=api_key)\n",
    "# print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 senteneces were found\n"
     ]
    }
   ],
   "source": [
    "# level 4 : Semantic Chunking  \n",
    "# åŸºæœ¬æƒ³æ³•æ˜¯è¯­ä¹‰ç›¸ä¼¼çš„ç‰‡æ®µåº”è¯¥åœ¨ä¸€èµ· ã€‚ä¸‹é¢æ˜¯åœ¨è¿ç»­å¥å­ä¸­å¯»æ‰¾æ–­ç‚¹çš„æ–¹æ³•ï¼Œ#1 å¥å­ é€’å½’çš„å’Œ #2 #3 æ¯”è¾ƒï¼Œå¯»æ‰¾åµŒå…¥è·ç¦»è¾ƒå¤§çš„æ–­ç‚¹ã€‚\n",
    "# è¶…è¿‡é˜ˆå€¼çš„è®¤ä¸ºæ˜¯æ–°è¯­ä¹‰çš„å¼€å§‹ã€‚ä¸ºäº†é¿å…å™ªå£°ï¼Œé€‰æ‹©æ¯ç»„3ä¸ªå¥å­ä¸ºä¸€ä¸ªçª—å£ï¼Œget embedding but abandoned first sentence. å®é™…æµ‹æ–‡ç« å¯èƒ½æ›´åŠ å¤æ‚\n",
    "\n",
    "import chardet \n",
    "\n",
    "with open(\"../data/txt/ä¸‰ä½“å…¨é›†.txt\", \"rb\") as f:\n",
    "    raw_text = f.read()\n",
    "    result = chardet.detect(raw_text)\n",
    "    charenc = result['encoding']\n",
    "\n",
    "try:  # try opening with the detected encoding\n",
    "    with open(\"../data/txt/ä¸‰ä½“å…¨é›†.txt\", \"r\", encoding=charenc) as f:\n",
    "        text = f.read()\n",
    "except UnicodeDecodeError:  # if error occurs, try with 'gb18030'\n",
    "    with open(\"../data/txt/ä¸‰ä½“å…¨é›†.txt\", \"r\", encoding='gb18030') as f:\n",
    "        text = f.read()\n",
    "\n",
    "#print(text[:2000])  # print a portion to verify if it's correct, you can adjust the range as needed\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "# Splitting the essay on '.', '?', and '!'\n",
    "single_sentences_list = re.split(r'(?<=[.?!])\\s+', text[:2000])\n",
    "print (f\"{len(single_sentences_list)} senteneces were found\")\n",
    "\n",
    "\n",
    "sentences = [{'sentence': x, 'index' : i} for i, x in enumerate(single_sentences_list)]\n",
    "sentences[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ–‡æœ¬åµŒå…¥\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings_model = OpenAIEmbeddings()\n",
    "\n",
    "\n",
    "embeddings = embeddings_model.embed_documents([\n",
    "    \"Hi there!\",\n",
    "    \"Oh, hello!\",\n",
    "    \"What's your name?\",\n",
    "    \"My friends call me World\",\n",
    "    \"Hello World!\"\n",
    "])\n",
    "\n",
    "print(len(embeddings), len(embeddings[0]))\n",
    "\n",
    "\n",
    "embedded_query = embeddings_model.embed_query(\"What was the name mentioned in the conversation?\")\n",
    "print(embedded_query[:5])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å‘é‡å­˜å‚¨  https://python.langchain.com/v0.1/docs/modules/data_connection/vectorstores/\n",
    "\n",
    "# pip install faiss-cpu\n",
    "\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = getpass.getpass('OpenAI API Key:')\n",
    "\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Load the document, split it into chunks, embed each chunk and load it into the vector store.\n",
    "raw_documents = TextLoader('../../../state_of_the_union.txt').load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "db = FAISS.from_documents(documents, OpenAIEmbeddings())\n",
    "\n",
    "\n",
    "\n",
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "docs = db.similarity_search(query)\n",
    "print(docs[0].page_content)\n",
    "\n",
    "\n",
    "embedding_vector = OpenAIEmbeddings().embed_query(query)\n",
    "docs = db.similarity_search_by_vector(embedding_vector)\n",
    "print(docs[0].page_content)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#pip install qdrant-client\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "db = await Qdrant.afrom_documents(documents, embeddings, \"http://localhost:6333\")\n",
    "\n",
    "# å¼‚æ­¥æ£€ç´¢\n",
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "docs = await db.asimilarity_search(query)\n",
    "print(docs[0].page_content)\n",
    "\n",
    "# åŸºäºVectorçš„å¼‚æ­¥æ£€ç´¢\n",
    "embedding_vector = embeddings.embed_query(query)\n",
    "docs = await db.asimilarity_search_by_vector(embedding_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ£€ç´¢å™¨ - https://python.langchain.com/v0.1/docs/modules/data_connection/retrievers/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç´¢å¼•\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.indexes import SQLRecordManager, index\n",
    "from langchain_core.documents import Document\n",
    "from langchain_elasticsearch import ElasticsearchStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "collection_name = \"test_index\"\n",
    "embedding = OpenAIEmbeddings()\n",
    "vectorstore = ElasticsearchStore(\n",
    "    es_url=\"http://localhost:9200\", index_name=\"test_index\", embedding=embedding\n",
    ")\n",
    "\n",
    "namespace = f\"elasticsearch/{collection_name}\"\n",
    "record_manager = SQLRecordManager(\n",
    "    namespace, db_url=\"sqlite:///record_manager_cache.sql\"\n",
    ")\n",
    "record_manager.create_schema()\n",
    "\n",
    "# ç¤ºä¾‹æ–‡æ¡£\n",
    "doc1 = Document(page_content=\"kitty\", metadata={\"source\": \"kitty.txt\"})\n",
    "doc2 = Document(page_content=\"doggy\", metadata={\"source\": \"doggy.txt\"})\n",
    "\n",
    "# ç´¢å¼•æ“ä½œ\n",
    "def _clear():\n",
    "    \"\"\"ä¸ºæ¸…ç†å†…å®¹æä¾›è¾…åŠ©æ–¹æ³•ã€‚è¯·å‚é˜…`full`æ¨¡å¼éƒ¨åˆ†äº†è§£å…¶å·¥ä½œåŸç†ã€‚\"\"\"\n",
    "    index([], record_manager, vectorstore, cleanup=\"full\", source_id_key=\"source\")\n",
    "\n",
    "index(\n",
    "    [doc1, doc1, doc1, doc1, doc1],\n",
    "    record_manager,\n",
    "    vectorstore,\n",
    "    cleanup=None,\n",
    "    source_id_key=\"source\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
