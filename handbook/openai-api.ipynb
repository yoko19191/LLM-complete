{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Client\n",
    "\n",
    "https://platform.openai.com/docs/api-reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "\n",
    "OPENAI_API_KEY = \"xinference\"\n",
    "OPENAI_BASE_URL = \"https://u39228-84cd-56ae2af7.westb.seetacloud.com:8443/v1\"\n",
    "\n",
    "# OPENAI_API_KEY = \"sk-520941c0feaa4cec82e7217979bb9c2d\"\n",
    "# OPENAI_BASE_URL = \"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n",
    "\n",
    "client = openai.Client(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=OPENAI_BASE_URL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(id='bce-embedding-base_v1', created=0, object='model', owned_by='xinference', model_type='embedding', address='0.0.0.0:36071', accelerators=['0'], model_name='bce-embedding-base_v1', dimensions=768, max_tokens=512, language=['zh', 'en'], model_revision=None, replica=1)\n",
      "Model(id='qwen2-7B-custom', created=0, object='model', owned_by='xinference', model_type='LLM', address='0.0.0.0:46057', accelerators=['0'], model_name='qwen2-7B-custom', model_lang=['en', 'zh'], model_ability=['chat', 'generate'], model_description='fine-tuned qwen2-7B-Instruct by ISOM', model_format='gptq', model_size_in_billions=7, model_family='qwen2-instruct', quantization='4', model_hub='huggingface', revision=None, context_length=32768, replica=1)\n",
      "Model(id='qwen2-instruct', created=0, object='model', owned_by='xinference', model_type='LLM', address='0.0.0.0:39661', accelerators=['1'], model_name='qwen2-instruct', model_lang=['en', 'zh'], model_ability=['chat', 'tools'], model_description='Qwen2 is the new series of Qwen large language models', model_format='awq', model_size_in_billions=7, model_family='qwen2-instruct', quantization='Int4', model_hub='modelscope', revision=None, context_length=32768, replica=1)\n"
     ]
    }
   ],
   "source": [
    "models = client.models.list()\n",
    "\n",
    "for model in models:\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8554216260376502\n",
      "0.6309478339480699\n",
      "0.6292141306079025\n"
     ]
    }
   ],
   "source": [
    "embedding_model = \"bce-embedding-base_v1\"\n",
    "\n",
    "\n",
    "def get_embedding(text: str, model: str) -> list[float]:\n",
    "    return client.embeddings.create(\n",
    "        input=text, \n",
    "        model=model).data[0].embedding\n",
    "\n",
    "\n",
    "# embeddings = client.embeddings.create(\n",
    "#     model=embedding_model,\n",
    "#     input=\"The food was delicious and the waiter...\",\n",
    "#     encoding_format=\"float\"\n",
    "# )\n",
    "\n",
    "\n",
    "sentence1 = \"i like dogs\"\n",
    "sentence2 = \"i like canine\"\n",
    "sentence3 = \"what a adorable puppy\"\n",
    "\n",
    "embedding1 = get_embedding(sentence1, embedding_model)\n",
    "embedding2 = get_embedding(sentence2, embedding_model)\n",
    "embedding3 = get_embedding(sentence3, embedding_model)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(np.dot(embedding1, embedding2))\n",
    "print(np.dot(embedding1, embedding3))\n",
    "print(np.dot(embedding2, embedding3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.8554216260376502\n",
    "0.6309478339480699\n",
    "0.6292141306079025\n",
    "\n",
    "\n",
    "0.9565686441672026\n",
    "0.8478909310324844\n",
    "0.8456562013355758"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'您好!我是文曦,由 服务型制造研究院(杭州)有限公司 开发的人工智能助手。'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model = \"qwen2-7B-custom\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=chat_model,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"你是谁?\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xinference Client"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_ground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
