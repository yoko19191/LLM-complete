{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Client\n",
    "\n",
    "https://platform.openai.com/docs/api-reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T05:19:04.896727Z",
     "start_time": "2024-07-19T05:19:04.852678Z"
    }
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "\n",
    "OPENAI_API_KEY = \"xinference\"\n",
    "OPENAI_BASE_URL = \"https://u39228-b3e1-e8902c07.westb.seetacloud.com:8443/v1\"\n",
    "\n",
    "# OPENAI_API_KEY = \"sk-\"\n",
    "# OPENAI_BASE_URL = \"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n",
    "\n",
    "\n",
    "# OPENAI_API_KEY = \"sk-\"\n",
    "# OPENAI_BASE_URL = \"https://api.openai.com/v1\"\n",
    "\n",
    "\n",
    "client = openai.Client(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=OPENAI_BASE_URL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T05:19:07.544023Z",
     "start_time": "2024-07-19T05:19:07.008771Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(id='bce-embedding-base_v1', created=0, object='model', owned_by='xinference', model_type='embedding', address='0.0.0.0:33619', accelerators=['0'], model_name='bce-embedding-base_v1', dimensions=768, max_tokens=512, language=['zh', 'en'], model_revision=None, replica=1)\n",
      "Model(id='qwen2-instruct', created=0, object='model', owned_by='xinference', model_type='LLM', address='0.0.0.0:46413', accelerators=['1'], model_name='qwen2-instruct', model_lang=['en', 'zh'], model_ability=['chat', 'tools'], model_description='Qwen2 is the new series of Qwen large language models', model_format='awq', model_size_in_billions=7, model_family='qwen2-instruct', quantization='Int4', model_hub='modelscope', revision=None, context_length=32768, replica=1)\n",
      "Model(id='qwen2-7B-custom', created=0, object='model', owned_by='xinference', model_type='LLM', address='0.0.0.0:37559', accelerators=['0'], model_name='qwen2-7B-custom', model_lang=['en', 'zh'], model_ability=['chat', 'generate'], model_description='fine-tuned qwen2-7B-Instruct by ISOM', model_format='gptq', model_size_in_billions=7, model_family='qwen2-instruct', quantization='4', model_hub='huggingface', revision=None, context_length=32768, replica=1)\n"
     ]
    }
   ],
   "source": [
    "models = client.models.list()\n",
    "\n",
    "for model in models:\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8554216260376504\n",
      "0.6309478339480697\n",
      "0.6292141306079027\n"
     ]
    }
   ],
   "source": [
    "embedding_model = \"bce-embedding-base_v1\"\n",
    "\n",
    "\n",
    "def get_embedding(text: str, model: str) -> list[float]:\n",
    "    return client.embeddings.create(\n",
    "        input=text, \n",
    "        model=model).data[0].embedding\n",
    "\n",
    "\n",
    "# embeddings = client.embeddings.create(\n",
    "#     model=embedding_model,\n",
    "#     input=\"The food was delicious and the waiter...\",\n",
    "#     encoding_format=\"float\"\n",
    "# )\n",
    "\n",
    "\n",
    "sentence1 = \"i like dogs\"\n",
    "sentence2 = \"i like canine\"\n",
    "sentence3 = \"what a adorable puppy\"\n",
    "\n",
    "embedding1 = get_embedding(sentence1, embedding_model)\n",
    "embedding2 = get_embedding(sentence2, embedding_model)\n",
    "embedding3 = get_embedding(sentence3, embedding_model)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(np.dot(embedding1, embedding2))\n",
    "print(np.dot(embedding1, embedding3))\n",
    "print(np.dot(embedding2, embedding3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.8554216260376502\n",
    "0.6309478339480699\n",
    "0.6292141306079025\n",
    "\n",
    "\n",
    "0.9565686441672026\n",
    "0.8478909310324844\n",
    "0.8456562013355758"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T05:21:19.337833Z",
     "start_time": "2024-07-19T05:21:18.256294Z"
    }
   },
   "outputs": [],
   "source": [
    "chat_model = \"qwen2-7B-custom\"\n",
    "\n",
    "\n",
    "prompt = \"生成一份国务院办公厅关于加强政府网站建设和管理工作的意见的公文，内容需涵盖以下要点：\\n- 强调政府网站的重要性，作为政务公开、社会管理和公共服务的平台。\\n- 提出政府网站建设的目标和指导思想，包括依法行政、提高服务水平、保障公众权利等。\\n- 要求健全政府网站体系，包括中央、省、市各级政府网站的功能定位和互联互通。\\n- 加强政府信息发布，确保信息的真实、及时和全面。\\n- 提高在线办事能力，实现行政许可项目的在线办理。\\n- 拓展公益服务，提供教育、科技、文化等领域的便民信息。\\n- 推进互动交流，开设在线访谈、网上调查等栏目。\\n- 改进网站展示形式，包括页面设计、域名设置等。\\n- 提升技术保障水平，确保网站稳定运行。\\n- 增强安全保障能力，防止网络攻击和系统故障。\\n- 完善运行管理机制，明确责任单位和绩效评估。\\n- 要求各地区、各部门制定实施办法，落实各项措施，提升政府网站建设和管理水平。\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=chat_model,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "  ]\n",
    ")\n",
    "\n",
    "text = completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[channel] 国务院文件 [issue_authority] 国务院办公厅 [subjects] 工业、信息\\\\信息化 [title] 国务院办公厅关于加强政府网站建设和管理工作的意见 [content] 国务院办公厅关于加强政府网站\\n建设和管理工作的意见\\n国办发〔2007〕15号\\n各省、自治区、直辖市人民政府，国务院各部委、各直属机构：\\n\\u3000\\u3000依托因特网建设的政府网站已经成为重要的政务公开平台、政府与公众沟通交流的重要渠道、提供在线服务的重要载体、推动政府部门信息化建设的重要力量。近年来，各地区、各部门切实加强政府网站建设，取得了明显成效。但也存在一些问题，如信息更新不及时、政民互动渠道不足、技术保障能力不足等。为加强政府网站建设和管理，全面提升政府网站服务水平，经国务院同意，现就有关事项通知如下：\\n\\u3000\\u3000一、充分认识政府网站的重要作用\\n\\u3000\\u3000（一）政府网站建设是推行政务公开、加强行政监督的重要平台；是创新便民服务方式、缓解社会矛盾、提升政府行政管理和服务水平的重要途径；是加快电子政务建设、实现政务提速、提高办事效率的有效举措。加强政府网站建设，有利于贯彻党的十七大关于健全行政监督体系、加强网络舆论监督的要求，有利于贯彻科学发展观，提高经济调控和管理的科学化水平，促进社会和谐，有利于利用现代信息技术手段更好地服务人民群众。\\n\\u3000\\u3000（二）建立覆盖全国各省（区、市）和国务院各部委、各直属机构的政府网站体系；网站平台、网站内容的共建共享和数据交换，信息资源共享，互联互通工作机制；建好用好环保部门综合集成的“政府网站群”。政府网站要解决群众上网有门、办事有人、反映情况能听到回音的问题，进一步增强公众的认同感和政府网站的影响力。\\n\\u3000\\u3000（三）各省（区、市）人民政府要严格执行《国务院领导同志在国务院网站开通仪式上的讲话》、《国务院办公厅、公信部关于进一步做好政府网站互联互通工作的意见》有关要求，按照统一的组织结构，组织技术力量集中力量做好行政许可项目的接入工作，并在2007年9月15日前在政府网站上公开广州、天津、江苏、山东、重庆的46项省级和市级行政许可; 2008年3月15日前完成省级和计划单列市行政许可事项的接入工作；在2009年12月31日前实现国务院部门行政许可事项的联网工作。同时及时对相应的办事指南进行调整和完善，在对应办事窗口处及时向社会公布相关信息。\\n\\u3000\\u3000（四）要加强对网络应用的宣传和引导，进一步增强公众的网络安全意识和使用规范的法律意识，更好的服务于民。要建立适用的应急预案机制。\\n\\u3000\\u3000二、健全政府网站管理组织架构\\n\\u3000\\u3000（一）国务院办公厅要完善相关程序，加强对有关网站的审核监管。要指导相关司\\n局做好与内外网隔离的技术审计、远程审计的相关检查工作。\\n\\u3000\\u3000（二）各省（区、市）人民政府都要制定和完善政府网站管理办法，建立完善政府网站管理协调联席会议制度，并落实属地化管理规定。\\n\\u3000\\u3000（三）国务院各部委、各直属机构要制定和完善相关办法，在本部门或本单位的门户网站上健全与国务院办公厅互动的代表团长栏目，以小论坛形式及时发布相关新闻和公开回答公众提出的常见问题。同时开展座谈会征求意见。2007年9月份前完成，9月份以后，将不断进行真实反馈的汇合和目前情况总结并逐步推广。\\n\\u3000\\u3000（四）要建立和完善政府网站错误跟踪机制，对公众能够反映出问题的政府网站应制定复查 Finds机制，由有关部门或人员对各错误空气制度进行复查；组织好问题的跟踪和后续管理工作。\\n\\u3000\\u3000三、加强对政府信息发布工作的管理\\n\\u3000\\u3000（一）要按照相关要求，科学规划，分期实施。进一步完善工作机制，及时准确发布国内外重要时事的重要新闻，遇有重大突发事件，要加强与新闻单位的沟通协调，增强权威性和公信力。\\n\\u3000\\u3000（二）将重要新闻报道与政府重要事项公开联动起来，提高时效性。2007年9\\n月1日前按照《国务院办公厅关于进一步做好重要信息上网公开工作的通知》公开网上的人民政府信息目录，并做好相关说明工作。\\n\\u3000\\u3000（三）逐步引入国家税务总局建构的信诺今天800系统的审计服务。\\n\\u3000\\u3000（四）建立完善新闻发布会制度，进一步明确新闻发布事项的发布主体和时间等要求，组织好发布活动。\\n\\u3000\\u3000四、实现行政许可项目的在线办理\\n\\u3000\\u3000（一）要完善配套政策措施，积极创造条件，使政府网站成为公众获取政府信息、参与管理和服务的重要实体渠道'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 豆包 SDK\n",
    "\n",
    "https://www.volcengine.com/docs/82379/1263482\n",
    "\n",
    "https://console.volcengine.com/ark/region:ark+cn-beijing/endpoint?current=1&pageSize=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install 'volcengine-python-sdk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- standard request -----\n",
      "常见的十字花科植物有很多，以下为您列举一些：\n",
      "1. 白菜：包括大白菜、小白菜等，是人们日常生活中常见的蔬菜。\n",
      "2. 萝卜：有白萝卜、胡萝卜等品种。\n",
      "3. 甘蓝：如卷心菜、紫甘蓝等。\n",
      "4. 芥菜：包括叶用芥菜、茎用芥菜等。\n",
      "5. 花椰菜：又称菜花。\n",
      "6. 西兰花：营养丰富，深受人们喜爱。\n",
      "7. 油菜：既可作为蔬菜食用，也可用于榨油。\n",
      "8. 诸葛菜：又名二月兰，常作为观赏植物种植。\n",
      "\n",
      "这些十字花科植物在人们的饮食和生活中都具有重要的地位。\n",
      "----- streaming request -----\n",
      "常见的十字花科植物有很多，以下为您列举一些：\n",
      "1. 白菜：包括大白菜、小白菜等，是人们日常生活中常见的蔬菜。\n",
      "2. 萝卜：有白萝卜、胡萝卜、青萝卜等品种。\n",
      "3. 甘蓝：如卷心菜、紫甘蓝等。\n",
      "4. 芥菜：包括芥菜疙瘩、雪里蕻等。\n",
      "5. 油菜：既是油料作物，嫩苗也可作为蔬菜食用。\n",
      "6. 花椰菜：又称菜花。\n",
      "7. 西兰花：营养丰富，深受人们喜爱。\n",
      "\n",
      "这些十字花科植物在人们的饮食中占据着重要的地位，富含维生素、矿物质等营养成分。\n"
     ]
    }
   ],
   "source": [
    "from volcenginesdkarkruntime import Ark\n",
    "\n",
    "import os\n",
    "\n",
    "# Authentication\n",
    "# 1.If you authorize your endpoint using an API key, you can set your api key to environment variable \"ARK_API_KEY\"\n",
    "# or specify api key by Ark(api_key=\"${YOUR_API_KEY}\").\n",
    "# Note: If you use an API key, this API key will not be refreshed.\n",
    "# To prevent the API from expiring and failing after some time, choose an API key with no expiration date.\n",
    "\n",
    "# 2.If you authorize your endpoint with Volcengine Identity and Access Management（IAM), set your api key to environment variable \"VOLC_ACCESSKEY\", \"VOLC_SECRETKEY\"\n",
    "# or specify ak&sk by Ark(ak=\"${YOUR_AK}\", sk=\"${YOUR_SK}\").\n",
    "# To get your ak&sk, please refer to this document([https://www.volcengine.com/docs/6291/65568](https://www.volcengine.com/docs/6291/65568))\n",
    "# For more information，please check this document（[https://www.volcengine.com/docs/82379/1263279](https://www.volcengine.com/docs/82379/1263279)）\n",
    "client = Ark(\n",
    "    api_key=os.getenv(\"ARK_API_KEY\")\n",
    ")\n",
    "\n",
    "ENDPOINT_ID = \"ep-20240714142438-db5bg\" # doubao-pro-128k\n",
    " \n",
    "\n",
    "# Non-streaming:\n",
    "print(\"----- standard request -----\")\n",
    "completion = client.chat.completions.create(\n",
    "    model=ENDPOINT_ID,\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"你是豆包，是由字节跳动开发的 AI 人工智能助手\"},\n",
    "        {\"role\": \"user\", \"content\": \"常见的十字花科植物有哪些？\"},\n",
    "    ],\n",
    ")\n",
    "print(completion.choices[0].message.content)\n",
    "\n",
    "# Streaming:\n",
    "print(\"----- streaming request -----\")\n",
    "stream = client.chat.completions.create(\n",
    "    model=ENDPOINT_ID,\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"你是豆包，是由字节跳动开发的 AI 人工智能助手\"},\n",
    "        {\"role\": \"user\", \"content\": \"常见的十字花科植物有哪些？\"},\n",
    "    ],\n",
    "    stream=True\n",
    ")\n",
    "for chunk in stream:\n",
    "    if not chunk.choices:\n",
    "        continue\n",
    "    print(chunk.choices[0].delta.content, end=\"\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- embeddings request -----\n"
     ]
    },
    {
     "ename": "ArkNotFoundError",
     "evalue": "Error code: 404 - {'error': {'code': 'InvalidEndpoint.NotFound', 'message': 'The request targeted an endpoint that does not exist or is invalid. Request id: 021721881558488bc6ef51f61ecfafe48ca0f0d9537b767684677', 'param': '', 'type': 'NotFound'}}, request_id: 20240725122557zXgr97dKgia1IcvHo6ot",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArkNotFoundError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# client = Ark(\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#     base_url=\"${BASE_URL}\",\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m----- embeddings request -----\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m$\u001b[39;49m\u001b[38;5;132;43;01m{YOUR_ENDPOINT_ID}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m花椰菜又称菜花、花菜，是一种常见的蔬菜。\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(resp)\n",
      "File \u001b[0;32m~/.pyenv/versions/mambaforge-22.9.0-3/envs/langchain/lib/python3.12/site-packages/volcenginesdkarkruntime/_utils/_utils.py:64\u001b[0m, in \u001b[0;36mwith_sts_token.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m     _insert_sts_token(args, kwargs)\n\u001b[0;32m---> 64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/mambaforge-22.9.0-3/envs/langchain/lib/python3.12/site-packages/volcenginesdkarkruntime/resources/embeddings.py:41\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[0;34m(self, input, model, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;129m@with_sts_token\u001b[39m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     40\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CreateEmbeddingResponse:\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/embeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/mambaforge-22.9.0-3/envs/langchain/lib/python3.12/site-packages/volcenginesdkarkruntime/_base_client.py:555\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m    537\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    538\u001b[0m         path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    545\u001b[0m         stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    546\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m    547\u001b[0m     opts \u001b[38;5;241m=\u001b[39m RequestOptions\u001b[38;5;241m.\u001b[39mconstruct(  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    548\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    549\u001b[0m         url\u001b[38;5;241m=\u001b[39mpath,\n\u001b[1;32m    550\u001b[0m         body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    551\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions,\n\u001b[1;32m    552\u001b[0m     )\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m--> 555\u001b[0m         ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    556\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/mambaforge-22.9.0-3/envs/langchain/lib/python3.12/site-packages/volcenginesdkarkruntime/_base_client.py:567\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    559\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    560\u001b[0m         cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    565\u001b[0m         stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    566\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/mambaforge-22.9.0-3/envs/langchain/lib/python3.12/site-packages/volcenginesdkarkruntime/_base_client.py:468\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    465\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m    467\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 468\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(\n\u001b[1;32m    469\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse, request_id\u001b[38;5;241m=\u001b[39mreq_id\n\u001b[1;32m    470\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m    473\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m    474\u001b[0m     response\u001b[38;5;241m=\u001b[39mresponse,\n\u001b[1;32m    475\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m    476\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m    477\u001b[0m )\n",
      "\u001b[0;31mArkNotFoundError\u001b[0m: Error code: 404 - {'error': {'code': 'InvalidEndpoint.NotFound', 'message': 'The request targeted an endpoint that does not exist or is invalid. Request id: 021721881558488bc6ef51f61ecfafe48ca0f0d9537b767684677', 'param': '', 'type': 'NotFound'}}, request_id: 20240725122557zXgr97dKgia1IcvHo6ot"
     ]
    }
   ],
   "source": [
    "from volcenginesdkarkruntime import Ark\n",
    "\n",
    "# client = Ark(\n",
    "#     base_url=\"${BASE_URL}\",\n",
    "# )\n",
    "\n",
    "print(\"----- embeddings request -----\")\n",
    "resp = client.embeddings.create(\n",
    "    model=\"${YOUR_ENDPOINT_ID}\",\n",
    "    input=[\"花椰菜又称菜花、花菜，是一种常见的蔬菜。\"]\n",
    ")\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESTful 请求"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_openai_chat_completion(url, api_key, prompt, model=\"gpt-4\"):\n",
    "    \n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"max_tokens\": 150,\n",
    "        \"n\": 1,\n",
    "        \"stop\": None,\n",
    "        \"temperature\": 0.7\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        completion = response.json()\n",
    "        return completion[\"choices\"][0][\"message\"][\"content\"]\n",
    "    else:\n",
    "        return f\"Error: {response.status_code}, {response.text}\"\n",
    "\n",
    "# 示例使用\n",
    "url = \"https://u39228-8ccc-bed8d1a0.westb.seetacloud.com:8443/v1/chat/completions\"\n",
    "api_key = \"xinference\"\n",
    "prompt = \"讲一个关于人工智能的笑话。\"\n",
    "\n",
    "response = get_openai_chat_completion(url=url, api_key=api_key, prompt=prompt, model=\"qwen2-instruct\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xinference Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groq \n",
    "\n",
    "pip install groq\n",
    "\n",
    "echo \"GROQ_API_KEY=<your-api-key-here>\" >> ~/.bashrc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models are crucial in today's digital landscape, and their importance can be understood from several perspectives:\n",
      "\n",
      "1. **Efficient Processing**: Fast language models can process and analyze vast amounts of text data quickly, which is essential for applications that require real-time or near-real-time processing, such as:\n",
      "\t* Sentiment analysis for social media monitoring\n",
      "\t* Chatbots and virtual assistants\n",
      "\t* Language translation\n",
      "\t* Text summarization\n",
      "2. **Scalability**: Fast language models can handle large volumes of data and scale to meet the demands of growing applications, making them ideal for:\n",
      "\t* Large-scale text analysis\n",
      "\t* Natural Language Processing (NLP) tasks\n",
      "\t* Machine learning model training\n",
      "3. **Improved User Experience**: Fast language models enable applications to respond quickly to user input, providing a better user experience and increasing user engagement:\n",
      "\t* Faster response times for chatbots and virtual assistants\n",
      "\t* Quicker text summarization and analysis\n",
      "\t* More efficient language translation\n",
      "4. **Cost Savings**: Fast language models can reduce computational costs by minimizing the time and resources required for processing and analysis:\n",
      "\t* Lower energy consumption\n",
      "\t* Reduced infrastructure costs\n",
      "\t* Increased productivity\n",
      "5. **Competitive Advantage**: Organizations that leverage fast language models can gain a competitive edge by:\n",
      "\t* Responding faster to customer inquiries\n",
      "\t* Analyzing market trends and sentiment in real-time\n",
      "\t* Developing more accurate and efficient NLP models\n",
      "6. **Research and Development**: Fast language models facilitate research and development in NLP by enabling:\n",
      "\t* Rapid experimentation and prototyping\n",
      "\t* Faster iteration and refinement of models\n",
      "\t* Exploration of new NLP applications and techniques\n",
      "7. **Edge AI and IoT**: Fast language models are essential for Edge AI and IoT applications, where processing power and latency are limited:\n",
      "\t* Real-time processing and analysis of sensor data\n",
      "\t* Efficient language processing for voice assistants and smart devices\n",
      "8. **Accessibility**: Fast language models can improve accessibility by enabling:\n",
      "\t* Faster language translation and interpretation\n",
      "\t* More efficient text-to-speech and speech-to-text systems\n",
      "\t* Enhanced language support for people with disabilities\n",
      "\n",
      "In summary, fast language models are crucial for efficient processing, scalability, improved user experience, cost savings, competitive advantage, research and development, Edge AI and IoT, and accessibility. As the demand for NLP applications continues to grow, the importance of fast language models will only continue to increase.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from groq import Groq\n",
    "\n",
    "client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama-3.1-70b-versatile\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_ground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
